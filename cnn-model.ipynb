{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for run in kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/silero-audio-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PART = 0.5 # part of full data used to train our model \n",
    "VAL_PART = 0.2 # part of train data for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/silero-audio-classifier/train.csv')\n",
    "_, train_df, _, _ = train_test_split(train_df, train_df['label'].values, test_size = TRAIN_PART, stratify = train_df['label'].values)\n",
    "train, val, _, _ = train_test_split(train_df, train_df['label'].values, test_size = VAL_PART, stratify = train_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(label, num_class = 3):\n",
    "    one_hot = torch.zeros(num_class)\n",
    "    one_hot[label] = 1\n",
    "    return one_hot\n",
    "\n",
    "def read_audio(path):\n",
    "            sr, wav = read(path)\n",
    "            assert sr == 16000\n",
    "            assert len(wav) == 16000 * 3\n",
    "            assert len(wav.shape) == 1\n",
    "            return wav\n",
    "        \n",
    "def read_audio_norm(path):\n",
    "            wav = read_audio(path)\n",
    "            abs_max = np.abs(wav).max()\n",
    "            wav = wav.astype('float32')\n",
    "            if abs_max > 0:\n",
    "                wav *= 1 / abs_max\n",
    "            return wav\n",
    "\n",
    "window_size = 0.02\n",
    "window_stride = 0.01\n",
    "sample_rate = 16000\n",
    "\n",
    "n_fft = int(sample_rate * (window_size + 1e-8))\n",
    "win_length = n_fft\n",
    "hop_length = int(sample_rate * (window_stride + 1e-8))\n",
    "\n",
    "kwargs = {\n",
    "    'n_fft': n_fft,\n",
    "    'hop_length': hop_length,\n",
    "    'win_length': n_fft\n",
    "}\n",
    "\n",
    "def stft(wav):\n",
    "    D = librosa.stft(wav,\n",
    "                     **kwargs)\n",
    "    mag, phase = librosa.magphase(D)    \n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, test = False, data_path = '/kaggle/input/silero-audio-classifier/train'):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "                \n",
    "        label_dict = {'speech':0,\n",
    "                      'music':1,\n",
    "                      'noise':2}\n",
    "        \n",
    "        wav = read_audio_norm(os.path.join(self.data_path, self.df.iloc[idx].wav_path))\n",
    "        mag = torch.tensor(stft(wav), dtype = torch.float32).unsqueeze(0)\n",
    "        \n",
    "        if not self.test:\n",
    "            label = self.df.iloc[idx].target #label_dict[self.df.iloc[idx].label]\n",
    "            label_one_hot = to_onehot(label)\n",
    "            return mag, label_one_hot, torch.tensor(label, dtype = torch.int)\n",
    "        \n",
    "        return mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_ch = 256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                      nn.Conv2d(1,n_ch,3,2,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.BatchNorm2d(n_ch),\n",
    "                      \n",
    "                      nn.Conv2d(n_ch,n_ch,3,2,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.BatchNorm2d(n_ch),\n",
    "                      \n",
    "                      nn.Conv2d(n_ch,n_ch,3,2,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.BatchNorm2d(n_ch),\n",
    "            \n",
    "                      nn.Conv2d(n_ch,n_ch,3,2,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.BatchNorm2d(n_ch),\n",
    "                      \n",
    "                      nn.Conv2d(n_ch,3,3,2,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.BatchNorm2d(3),\n",
    "        \n",
    "                      nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "                      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x).squeeze(-1).squeeze(-1)\n",
    "        return self.softmax(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SoundDataset(train)\n",
    "val_dataset = SoundDataset(val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 15\n",
    "lr = 3e-4\n",
    "\n",
    "model = ConvModel()\n",
    "optimizer = Adam(model.parameters(), lr = lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "vall accuracy is 0.9756043956043956\n",
      "Model saved at 0 epoch\n",
      "Training epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type ConvModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "vall accuracy is 0.9862637362637363\n",
      "Model saved at 1 epoch\n",
      "Training epoch 2...\n",
      "Validation...\n",
      "vall accuracy is 0.9912087912087912\n",
      "Model saved at 2 epoch\n",
      "Training epoch 3...\n",
      "Validation...\n",
      "vall accuracy is 0.993992673992674\n",
      "Model saved at 3 epoch\n",
      "Training epoch 4...\n",
      "Validation...\n",
      "vall accuracy is 0.9942124542124542\n",
      "Model saved at 4 epoch\n",
      "Training epoch 5...\n",
      "Validation...\n",
      "vall accuracy is 0.9950549450549451\n",
      "Model saved at 5 epoch\n",
      "Training epoch 6...\n",
      "Validation...\n",
      "vall accuracy is 0.9947985347985348\n",
      "Training epoch 7...\n",
      "Validation...\n",
      "vall accuracy is 0.9932967032967033\n",
      "Epoch     8: reducing learning rate of group 0 to 6.0000e-05.\n",
      "Training epoch 8...\n",
      "Validation...\n",
      "vall accuracy is 0.9955677655677656\n",
      "Model saved at 8 epoch\n",
      "Training epoch 9...\n",
      "Validation...\n",
      "vall accuracy is 0.9952747252747253\n",
      "Training epoch 10...\n",
      "Validation...\n",
      "vall accuracy is 0.995934065934066\n",
      "Model saved at 10 epoch\n",
      "Training epoch 11...\n",
      "Validation...\n",
      "vall accuracy is 0.9936263736263736\n",
      "Training epoch 12...\n",
      "Validation...\n",
      "vall accuracy is 0.9935897435897436\n",
      "Epoch    13: reducing learning rate of group 0 to 1.2000e-05.\n",
      "Training epoch 13...\n",
      "Validation...\n",
      "vall accuracy is 0.9943956043956044\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#tkepoch = tqdm(range(n_epoch), total = n_epoch)\n",
    "model.to(device)\n",
    "best_val_acc = 0\n",
    "patience = 3\n",
    "\n",
    "for i in range(n_epoch):\n",
    "     \n",
    "    \n",
    "    print(f\"Training epoch {i}...\")\n",
    "    epoch_train_loss = 0\n",
    "    model.train()\n",
    "    #tkloader = tqdm(train_loader, total = len(train_loader))\n",
    "    for x, y, _ in train_loader:\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    #print(f\"Epoch {i} loss is {epoch_train_loss}\")\n",
    "    print(\"Validation...\")\n",
    "    model.eval()\n",
    "    #tkval = tqdm(val_loader, total = len(val_loader))\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for x, y, l in val_loader:\n",
    "        with torch.no_grad():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            #print(y_pred.shape)\n",
    "            batch_pred = list(y_pred.argmax(axis = 1).cpu().detach().numpy())\n",
    "            batch_labels = list(l.cpu().detach().numpy())\n",
    "            #print(batch_pred.shape, batch_labels.shape)\n",
    "            preds = preds + batch_pred\n",
    "            labels = labels + batch_labels\n",
    "        \n",
    "    val_acc = accuracy_score(labels, preds)\n",
    "    print(f\"vall accuracy is {val_acc}\") \n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        patience = 3\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, 'model.pth')\n",
    "        print(f\"Model saved at {i} epoch\")\n",
    "        \n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
